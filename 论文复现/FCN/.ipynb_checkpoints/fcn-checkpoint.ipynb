{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim \n",
    "from torchvision import datasets, transforms, models\n",
    "import time\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convrelu(in_channels, out_channels, kernel, padding, stride=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel, stride=stride, padding=padding),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or inchannel != outchannel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(outchannel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MyFCN_diy_all(nn.Module):\n",
    "    def __init__(self, ResidualBlock=ResidualBlock, num_classes=30):\n",
    "        super().__init__()\n",
    "        self.inchannel = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.layer1 = self.make_layer(ResidualBlock, 64,  1, stride=1)\n",
    "        self.layer2 = self.make_layer(ResidualBlock, 128, 1, stride=2)\n",
    "        self.layer3 = self.make_layer(ResidualBlock, 256, 1, stride=2)\n",
    "        self.layer4 = self.make_layer(ResidualBlock, 512, 1, stride=2)\n",
    "        #self.fc = nn.Linear(512, 10)\n",
    "        \n",
    "        \n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)   #strides=[1,1]\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inchannel, channels, stride))\n",
    "            self.inchannel = channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        #out = out.view(out.size(0), -1)\n",
    "        #out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = models.resnet50(pretrained=True)\n",
    "ch = list(m.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "Linear(in_features=2048, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ch)):\n",
    "    print(ch[i]) #0 3 5 6 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilinear_kernel(in_channels, out_channels, kernel_size):\n",
    "    '''\n",
    "    return a bilinear filter tensor\n",
    "    '''\n",
    "    factor = (kernel_size + 1) // 2\n",
    "    if kernel_size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:kernel_size, :kernel_size]\n",
    "    filt = (1 - abs(og[0] - center) / factor) * (1 - abs(og[1] - center) / factor)\n",
    "    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size), dtype='float32')\n",
    "    weight[range(in_channels), range(out_channels), :, :] = filt\n",
    "    return torch.from_numpy(weight).cuda()\n",
    "\n",
    "class MyFCN(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        self.n_class = n_class\n",
    "        super().__init__()\n",
    "        self.base_model = models.resnet50(pretrained=True)\n",
    "        self.base_layers = list(self.base_model.children())\n",
    "        \n",
    "        self.layer00 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=100, bias=False)\n",
    "        self.layer0 = nn.Sequential(*self.base_layers[1:4]) # size=(N, 64, x.H/4, x.W/4)\n",
    "        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
    "        \n",
    "        self.layer1 = nn.Sequential(*self.base_layers[4]) # size=(N, 256, x.H/4, x.W/4)\n",
    "        self.layer1_1x1 = convrelu(256, 256, 1, 0)\n",
    "        \n",
    "        self.layer2 = self.base_layers[5]  # size=(N, 512, x.H/8, x.W/8)\n",
    "        self.layer2_1x1 = convrelu(512, 512, 1, 0)\n",
    "        \n",
    "        self.layer3 = self.base_layers[6]  # size=(N, 1024, x.H/16, x.W/16)\n",
    "        self.layer3_1x1 = convrelu(1024, 1024, 1, 0)\n",
    "        \n",
    "        self.layer4 = self.base_layers[7]  # size=(N, 2048, x.H/32, x.W/32)\n",
    "        self.layer4_1x1 = convrelu(2048, 2048, 1, 0)\n",
    "        \n",
    "        self.conv0 = convrelu(2048, 4096, 7, 0)\n",
    "        #self.conv0 = convrelu(2048, 4096, 1, 0)\n",
    "        self.conv1 = convrelu(4096, 4096, 1, 0)\n",
    "        \n",
    "        self.scores1 = nn.Conv2d(4096, n_class, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.scores2 = nn.Conv2d(1024, n_class, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.scores3 = nn.Conv2d(512, n_class, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        \n",
    "        self.upsample_8x = nn.ConvTranspose2d(n_class, n_class, 16, 8, 4, bias=False)\n",
    "        self.upsample_8x.weight.data = bilinear_kernel(n_class, n_class, 16) # 使用双线性 kernel\n",
    "        \n",
    "        self.upsample_4x = nn.ConvTranspose2d(n_class, n_class, 4, 2, 1, bias=False)\n",
    "        self.upsample_4x.weight.data = bilinear_kernel(n_class, n_class, 4) # 使用双线性 kernel\n",
    "        \n",
    "        self.upsample_2x = nn.ConvTranspose2d(n_class, n_class, 4, 2, 1, bias=False)   \n",
    "        self.upsample_2x.weight.data = bilinear_kernel(n_class, n_class, 4) # 使用双线性 kernel\n",
    "        \n",
    "    def forward(self, input):\n",
    "        # the base net\n",
    "        layer0 = self.layer00(input)\n",
    "        layer0 = self.layer0(layer0)\n",
    "        layer0 = self.layer0_1x1(layer0) \n",
    "        \n",
    "        layer1 = self.layer1(layer0)\n",
    "        layer1 = self.layer1_1x1(layer1)\n",
    "        \n",
    "        layer2 = self.layer2(layer1)\n",
    "        layer2 = self.layer2_1x1(layer2)\n",
    "        \n",
    "        layer3 = self.layer3(layer2)\n",
    "        layer3 = self.layer3_1x1(layer3)\n",
    "        \n",
    "        layer4 = self.layer4(layer3)\n",
    "        layer4 = self.layer4_1x1(layer4)\n",
    "\n",
    "        # fully conv\n",
    "        fc5 = self.conv0(layer4)\n",
    "        fc5 = F.dropout(fc5,p=0.5)\n",
    "        fc5 = self.conv1(fc5)\n",
    "        fc5 = F.dropout(fc5,p=0.5)\n",
    "        fc5 = self.scores1(fc5)\n",
    "        fc5 = self.upsample_2x(fc5)\n",
    "        \n",
    "        fc6 = self.scores2(layer3)\n",
    "        fc6 = fc6[:,:,abs(fc6.size()[2]-fc5.size()[2])//2:fc5.size()[2]+abs(fc6.size()[2]-fc5.size()[2])//2,abs(fc6.size()[3]-fc5.size()[3])//2:fc5.size()[3]+abs(fc6.size()[3]-fc5.size()[3])//2]\n",
    "        fc6 = fc6 + fc5\n",
    "        fc6 = self.upsample_4x(fc6)\n",
    "\n",
    "        fc7 = self.scores3(layer2)\n",
    "        fc7 = fc7[:,:,abs(fc7.size()[2]-fc6.size()[2])//2:fc6.size()[2]+abs(fc7.size()[2]-fc6.size()[2])//2,abs(fc7.size()[3]-fc6.size()[3])//2:fc6.size()[3]+abs(fc7.size()[3]-fc6.size()[3])//2]\n",
    "        fc7 = fc7 + fc6\n",
    "        fc7 = self.upsample_8x(fc7)\n",
    "        \n",
    "        out = fc7[:,:,abs(fc7.size()[2]-input.size()[2])//2:input.size()[2]+abs(fc7.size()[2]-input.size()[2])//2,abs(fc7.size()[3]-input.size()[3])//2:input.size()[3]+abs(fc7.size()[3]-input.size()[3])//2]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /home/hyf/.cache/torch/checkpoints/resnet50-19c8e357.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "net = MyFCN(20)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net = net.to(device)\n",
    "#summary(net, input_size=(3, 224, 224))\n",
    "#x = Variable(torch.randn(1,3,300,300))\n",
    "\n",
    "#model(x)\n",
    "#vis_graph = make_dot(model(x), params=dict(model.named_parameters()))\n",
    "#vis_graph.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 224, 224])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.randn(1,3,224,224)).cuda()\n",
    "result = net(x)\n",
    "result.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分割线\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_root = '/home/hyfok/Notebook/LIP'\n",
    "\n",
    "def read_images(root=voc_root, train=True):\n",
    "    txt_fname = root + '/TrainVal_images/' + ('train_id.txt' if train else 'val_id.txt')\n",
    "    with open(txt_fname, 'r') as f:\n",
    "        images = f.read().split()\n",
    "    data = [os.path.join(root, 'TrainVal_images/TrainVal_images', ('train_images/' if train else 'val_images/')+i+'.jpg') for i in images]\n",
    "    label = [os.path.join(root, 'TrainVal_parsing_annotations/TrainVal_parsing_annotations', ('train_segmentations/' if train else 'val_segmentations/')+i+'.png') for i in images]\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_crop(data, label, height, width):\n",
    "    \n",
    "    #data is PIL.Image object\n",
    "    #label is PIL.Image object\n",
    "    \n",
    "    data, rect = transforms.RandomCrop((height, width))(data)\n",
    "    label = transforms.FixedCrop(*rect)(label)\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['background','Hat','Hair','Glove','Sunglasses','UpperClothes',\n",
    "           'Dress','Coat','Socks','Pants','Jumpsuits','Scarf','Skirt',\n",
    "           'Face','Left-arm','Right-arm','Left-leg','Right-leg',\n",
    "           'Left-shoe','Right-shoe']\n",
    "\n",
    "# RGB color for each class\n",
    "colormap = [[0,0,0],[128,0,0],[0,128,0], [128,128,0], [0,0,128],\n",
    "            [128,0,128],[0,128,128],[128,128,128],[64,0,0],[192,0,0],\n",
    "            [64,128,0],[192,128,0],[64,0,128],[192,0,128],\n",
    "            [64,128,128],[192,128,128],[0,64,0],[128,64,0],\n",
    "            [0,192,0],[128,192,128]]\n",
    "\n",
    "len(classes), len(colormap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def png2color(im):\n",
    "    data = np.array(im, dtype='int32')\n",
    "    return np.array([colormap[i] for cols in data.tolist() for i in cols], dtype='uint8').reshape(data.shape[0],data.shape[1],3) # 根据索引得到color图\n",
    "\n",
    "def png2label(im):\n",
    "    L = np.asarray(np.array(im), np.int64)\n",
    "    return  L.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_im = Image.open('/home/hyfok/Notebook/LIP/TrainVal_parsing_annotations/TrainVal_parsing_annotations/train_segmentations/77_471474.png').convert('L')\n",
    "color_image = png2color(label_im)\n",
    "print(png2label(label_im).shape)\n",
    "Image.fromarray(color_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_transforms(im, label):\n",
    "    #im, label = rand_crop(im, label, *crop_size)\n",
    "    im_tfs = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    im = im_tfs(im)\n",
    "    label = png2label(label)\n",
    "    label = torch.from_numpy(label)\n",
    "    return im, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIPSegDataset(Dataset):\n",
    "    \n",
    "    # LIP dataset\n",
    "    \n",
    "    def __init__(self, train, transforms):\n",
    "        #self.crop_size = crop_size\n",
    "        self.transforms = transforms\n",
    "        data_list, label_list = read_images(train=train)\n",
    "        self.data_list = data_list\n",
    "        self.label_list = label_list\n",
    "        print('Read ' + str(len(self.data_list)) + ' images')\n",
    "        \n",
    "    def _filter(self, images): # 过滤掉图片大小小于 crop 大小的图片\n",
    "        return [im for im in images if (Image.open(im).size[1] >= self.crop_size[0] and \n",
    "                                        Image.open(im).size[0] >= self.crop_size[1])]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data_list[idx]\n",
    "        label = self.label_list[idx]\n",
    "        img = Image.open(img)\n",
    "        label = Image.open(label).convert('L')\n",
    "        img, label = self.transforms(img, label)\n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化数据集\n",
    "\n",
    "lip_train = LIPSegDataset(True, img_transforms)\n",
    "lip_test = LIPSegDataset(False, img_transforms)\n",
    "\n",
    "train_data = DataLoader(lip_train, 1, shuffle=True, num_workers=8)\n",
    "valid_data = DataLoader(lip_test, 1, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fast_hist(label_true, label_pred, n_class):\n",
    "    mask = (label_true >= 0) & (label_true < n_class)\n",
    "    hist = np.bincount(\n",
    "        n_class * label_true[mask].astype(int) +\n",
    "        label_pred[mask], minlength=n_class ** 2).reshape(n_class, n_class)\n",
    "    return hist\n",
    "\n",
    "\n",
    "def label_accuracy_score(label_trues, label_preds, n_class):\n",
    "    # Returns accuracy score evaluation result.\n",
    "      # overall accuracy\n",
    "      # mean accuracy\n",
    "      # mean IU\n",
    "      # fwavacc\n",
    "\n",
    "    hist = np.zeros((n_class, n_class))\n",
    "    for lt, lp in zip(label_trues, label_preds):\n",
    "        hist += _fast_hist(lt.flatten(), lp.flatten(), n_class)\n",
    "    acc = np.diag(hist).sum() / hist.sum()\n",
    "    acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
    "    acc_cls = np.nanmean(acc_cls)\n",
    "    iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n",
    "    mean_iu = np.nanmean(iu)\n",
    "    freq = hist.sum(axis=1) / hist.sum()\n",
    "    fwavacc = (freq[freq > 0] * iu[freq > 0]).sum()\n",
    "    return acc, acc_cls, mean_iu, fwavacc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分割线\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy2d(input, target, weight=None, size_average=True):\n",
    "    # input: (n, c, h, w), target: (n, h, w)\n",
    "    n, c, h, w = input.size()\n",
    "    # log_p: (n, c, h, w)\n",
    "    log_p = F.log_softmax(input, dim=1)\n",
    "    # log_p: (n*h*w, c)\n",
    "    log_p = log_p.transpose(1, 2).transpose(2, 3).contiguous()\n",
    "    log_p = log_p[target.view(n, h, w, 1).repeat(1, 1, 1, c) >= 0]\n",
    "    log_p = log_p.view(-1, c)\n",
    "    # target: (n*h*w,)\n",
    "    mask = target >= 0\n",
    "    target = target[mask]\n",
    "    loss = F.nll_loss(log_p, target, weight=weight, reduction='sum')\n",
    "    if size_average:\n",
    "        loss /= mask.data.sum()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "gamma      = 0.5\n",
    "epochs     = 500\n",
    "lr         = 1e-4\n",
    "momentum   = 0\n",
    "w_decay    = 1e-5\n",
    "step_size  = 50\n",
    "use_gpu = True\n",
    "\n",
    "BATCH_SIZE=512 #大概需要2G的显存\n",
    "EPOCHS=20 # 总共训练批次\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # 让torch判断是否使用GPU，建议使用GPU环境，因为会快很多\n",
    "\n",
    "criterion = cross_entropy2d\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=lr, momentum=momentum, weight_decay=w_decay)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)  # decay LR by a factor of 0.5 every 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 20, 586, 134]), torch.Size([1, 586, 134]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs,labels = iter(train_data).next()\n",
    "outputs = net(inputs.cuda())\n",
    "outputs.size(),labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([78524, 20])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.transpose(1, 2).transpose(2, 3).contiguous()[labels.view(1, 586, 134, 1).repeat(1, 1, 1, 20) >= 0].view(-1, 20).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    for epoch in range(epochs):\n",
    "        scheduler.step()\n",
    "\n",
    "        ts = time.time()\n",
    "        for iter, batch in enumerate(train_data):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if use_gpu:\n",
    "                inputs = Variable(batch[0].cuda())\n",
    "                labels = Variable(batch[1].cuda())\n",
    "            else:\n",
    "                inputs, labels = Variable(batch[0]), Variable(batch[1])\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if iter % 10 == 0:\n",
    "                print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss.data[0]))\n",
    "        \n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "        torch.save(fcn_model, model_path)\n",
    "\n",
    "        val(epoch)\n",
    "\n",
    "\n",
    "def val(epoch):\n",
    "    fcn_model.eval()\n",
    "    total_ious = []\n",
    "    pixel_accs = []\n",
    "    for iter, batch in enumerate(val_loader):\n",
    "        if use_gpu:\n",
    "            inputs = Variable(batch['X'].cuda())\n",
    "        else:\n",
    "            inputs = Variable(batch['X'])\n",
    "\n",
    "        output = fcn_model(inputs)\n",
    "        output = output.data.cpu().numpy()\n",
    "\n",
    "        N, _, h, w = output.shape\n",
    "        pred = output.transpose(0, 2, 3, 1).reshape(-1, n_class).argmax(axis=1).reshape(N, h, w)\n",
    "\n",
    "        target = batch['l'].cpu().numpy().reshape(N, h, w)\n",
    "        for p, t in zip(pred, target):\n",
    "            total_ious.append(iou(p, t))\n",
    "            pixel_accs.append(pixel_acc(p, t))\n",
    "\n",
    "    # Calculate average IoU\n",
    "    total_ious = np.array(total_ious).T  # n_class * val_len\n",
    "    ious = np.nanmean(total_ious, axis=1)\n",
    "    pixel_accs = np.array(pixel_accs).mean()\n",
    "    print(\"epoch{}, pix_acc: {}, meanIoU: {}, IoUs: {}\".format(epoch, pixel_accs, np.nanmean(ious), ious))\n",
    "    IU_scores[epoch] = ious\n",
    "    np.save(os.path.join(score_dir, \"meanIU\"), IU_scores)\n",
    "    pixel_scores[epoch] = pixel_accs\n",
    "    np.save(os.path.join(score_dir, \"meanPixel\"), pixel_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
